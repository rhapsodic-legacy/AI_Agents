# Walkthrough of the LangChain Agent Code

This code builds a LangChain agent using Google's Gemini 1.5 Flash model, extending the concepts from "Part 1" (a basic Gemini-based agent) by incorporating three tools: a calculator, a web search tool using DuckDuckGo, and a file reader. The agent is designed for university students to explore how AI agents can leverage tools for practical tasks.

## 1. Installation and Imports

```python
!pip install langchain langchain-google-genai duckduckgo-search

import time
import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents import initialize_agent, AgentType
from langchain.tools import tool
from langchain.memory import ConversationBufferMemory
from duckduckgo_search import DDGS
```

**What it does:** Installs required packages (langchain, langchain-google-genai, duckduckgo-search) and imports necessary modules.

**Why:** These libraries provide the framework for building the agent (langchain), connecting to Gemini (langchain-google-genai), and performing web searches (duckduckgo-search). Other imports support file handling, tool creation, and memory management.

**Note:** DuckDuckGo is chosen for web search because it's free and doesn't require an API key, making it accessible for students.

## 2. Initialize the Gemini LLM

```python
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",
    google_api_key="YOUR_API_KEY_HERE"  # Replace with your key
)
```

**What it does:** Sets up the Gemini 1.5 Flash model as the language model (LLM) for the agent, using a provided API key.

**Why:** The LLM serves as the reasoning engine for the agent, processing queries and deciding which tools to use. Gemini 1.5 Flash is fast and cost-effective, ideal for educational purposes. (Students should replace the placeholder API key with their own.)

**Note:** Covered in Part 1, so students are familiar with this step.

## 3. Define Tools

The agent uses three tools, each decorated with `@tool` to integrate with LangChain.

### a. Calculator Tool

```python
@tool
def calculator(query: str) -> str:
    """Evaluates a math expression."""
    try:
        return str(eval(query))
    except:
        return "Invalid expression"
```

**What it does:** Evaluates a mathematical expression (e.g., "5 + 3 * 2") using Python's `eval()` function and returns the result as a string. Errors return "Invalid expression."

**Why:** Demonstrates a simple tool for precise computations, reinforcing Part 1's concepts. It's useful for tasks requiring exact answers, like math problems.

**Note:** The use of `eval()` is simplified for teaching but should be sanitized in production to avoid security risks.

### b. Web Search Tool

```python
@tool
def web_search(query: str) -> str:
    """Searches the web for information."""
    with DDGS() as ddgs:
        results = ddgs.text(query, max_results=3)
    return str([r["title"] + ": " + r["href"] for r in results])
```

**What it does:** Uses the duckduckgo-search library to perform a web search for the given query, returning up to three results as a string containing titles and URLs.

**Why:** Introduces students to external data retrieval, a powerful feature for agents. DuckDuckGo's simplicity (no API key) makes it ideal for classroom use. The tool shows how agents can access real-time information beyond their training data.

**Note:** The `max_results=3` limits output for brevity, and the string format ensures compatibility with LangChain's tool output requirements.

### c. File Reader Tool

```python
@tool
def file_reader(filename: str) -> str:
    """Reads content from a text file."""
    if not os.path.exists(filename):
        return f"File '{filename}' does not exist."
    try:
        with open(filename, 'r') as file:
            return file.read()
    except Exception as e:
        return f"Error reading file: {str(e)}"
```

**What it does:** Reads and returns the content of a specified text file. If the file doesn't exist or an error occurs, it returns an appropriate error message. (!NOTE! The 'example.txt' file is included in the 'B_Langchain_Expanded' folder, but will need to be placed wherever the 'langchain_expanded.ipynb' file is.)

**Why:** Teaches students how agents can interact with local data, a common real-world use case (e.g., reading logs or configs). It complements the web search tool by showing another data source.

**Note:** Error handling ensures robustness, and the tool is kept simple to focus on functionality.

### Tool List

```python
tools = [calculator, web_search, file_reader]
```

**What it does:** Combines the three tools into a list for the agent to use.

**Why:** LangChain agents require a list of tools to decide which to invoke based on the query.

## 4. Initialize Memory

```python
memory = ConversationBufferMemory()
```

**What it does:** Creates a ConversationBufferMemory object to store the agent's conversation history.

**Why:** Enables the agent to maintain context across queries, which is useful for follow-up questions (though not heavily utilized in this example). It introduces students to memory management in agents.

**Note:** Briefly mentioned in Part 1, but its inclusion here sets the stage for more advanced memory use in future lessons.

## 5. Initialize the Agent

```python
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    memory=memory,
    verbose=True
)
```

**What it does:** Sets up the LangChain agent with the Gemini LLM, the three tools, and memory. Uses the ZERO_SHOT_REACT_DESCRIPTION agent type and enables verbose output for debugging.

**Why:** The ZERO_SHOT_REACT_DESCRIPTION agent type allows the agent to reason about which tool to use based on tool descriptions, without requiring training examples. Verbose mode helps students see the agent's decision-making process (e.g., which tool it selects and why).

**Note:** Students are familiar with agent initialization from Part 1, but the addition of multiple tools and memory is new.

## 6. Test the Agent

```python
if __name__ == "__main__":
    # Create example.txt if it doesn't exist
    if not os.path.exists("example.txt"):
        with open("example.txt", "w") as f:
            f.write("Hello, this is a test file!\nIt contains some text for the file_reader tool to read.")

    queries = [
        "What is 5 + 3 * 2?",
        "Search the web for Python tutorials",
        "Read the content of example.txt"
    ]
    
    for query in queries:
        response = agent.run(query)
        print(f"Query: {query}\nResponse: {response}\n")
        time.sleep(5)  # Avoid hitting API quota
```

**What it does:**
- Creates a sample example.txt file if it doesn't exist, containing test content for the file reader tool
- Defines three test queries to demonstrate each tool: a math problem (calculator), a web search (DuckDuckGo), and a file read (file reader)
- Runs each query through the agent, prints the response, and pauses for 5 seconds to avoid exceeding Gemini's API quota

**Why:**
- The test file ensures the file reader tool has something to read, making the demo self-contained
- The queries showcase the agent's ability to select the appropriate tool for different tasks, reinforcing the concept of tool-based reasoning
- The `time.sleep(5)` is a practical workaround for API rate limits, teaching students about real-world constraints

**Note:** The queries are simple and clear, designed to help students understand tool selection without overwhelming them.

## Complete Code

```python
!pip install langchain langchain-google-genai duckduckgo-search

import time
import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents import initialize_agent, AgentType
from langchain.tools import tool
from langchain.memory import ConversationBufferMemory
from duckduckgo_search import DDGS

# Initialize the Gemini LLM
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",
    google_api_key="YOUR_API_KEY_HERE"  # Replace with your key
)

# Define tools
@tool
def calculator(query: str) -> str:
    """Evaluates a math expression."""
    try:
        return str(eval(query))
    except:
        return "Invalid expression"

@tool
def web_search(query: str) -> str:
    """Searches the web for information."""
    with DDGS() as ddgs:
        results = ddgs.text(query, max_results=3)
    return str([r["title"] + ": " + r["href"] for r in results])

@tool
def file_reader(filename: str) -> str:
    """Reads content from a text file."""
    if not os.path.exists(filename):
        return f"File '{filename}' does not exist."
    try:
        with open(filename, 'r') as file:
            return file.read()
    except Exception as e:
        return f"Error reading file: {str(e)}"

# Combine tools
tools = [calculator, web_search, file_reader]

# Initialize memory
memory = ConversationBufferMemory()

# Initialize the agent
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    memory=memory,
    verbose=True
)

# Test the agent
if __name__ == "__main__":
    # Create example.txt if it doesn't exist
    if not os.path.exists("example.txt"):
        with open("example.txt", "w") as f:
            f.write("Hello, this is a test file!\nIt contains some text for the file_reader tool to read.")

    queries = [
        "What is 5 + 3 * 2?",
        "Search the web for Python tutorials",
        "Read the content of example.txt"
    ]
    
    for query in queries:
        response = agent.run(query)
        print(f"Query: {query}\nResponse: {response}\n")
        time.sleep(5)  # Avoid hitting API quota
```

## Why This Code Matters

This code builds on Part 1 by showing how agents can go beyond basic LLM responses to perform specialized tasks using tools. The calculator reinforces familiar concepts, while the web search and file reader introduce new capabilities (external data access and local file interaction). Using DuckDuckGo keeps the setup accessible, and the memory component hints at more advanced features. The verbose output and test queries help students see the agent's reasoning process, making it an effective teaching tool.

## Where to Go from Here

Having built and tested a multi-tool LangChain agent, students can explore the following to deepen their understanding and skills:

### Enhance Tool Functionality
- **Calculator:** Add support for more complex math (e.g., trigonometric functions) using libraries like `math` or `sympy`. Introduce input validation to make `eval()` safer.
- **Web Search:** Expand the web search tool to summarize results or filter by specific domains (e.g., .edu for academic content).
- **File Reader:** Extend the file reader to handle different file types (e.g., CSV, JSON) or write to files.

### Explore Advanced Agent Types
- Try other LangChain agent types, like `CONVERSATIONAL_REACT_DESCRIPTION`, to leverage memory for multi-turn conversations.
- Experiment with `OPENAI_FUNCTIONS` if using a compatible model, to see how function-calling differs from ReAct.

### Add More Tools
- Integrate APIs (e.g., weather, Wikipedia) to show how agents can pull in diverse data.
- Create a tool for executing Python code, allowing the agent to solve programming tasks dynamically.

### Improve Memory Management
- Use memory to handle follow-up questions (e.g., "Tell me more about the Python tutorials you found").
- Explore `ConversationSummaryMemory` to summarize long conversations, reducing token usage.

### Build a User Interface
- Deploy the agent in a web app using frameworks like Streamlit or Flask, making it interactive for end users.
- Add a frontend where users can upload files for the file reader or input queries via a chat interface.

### Optimize and Debug
- Analyze the verbose output to understand the agent's tool selection logic and improve tool descriptions for better accuracy.
- Handle edge cases (e.g., invalid file paths, no search results) more robustly.

### Real-World Projects
- Build an agent for a specific domain (e.g., a study assistant that searches academic papers, reads notes, and solves math problems).
- Create a task automation agent that combines tools like email sending, calendar scheduling, and web scraping.

### Learn About Production Considerations
- Research API rate limits and costs for Gemini or other LLMs to understand scaling challenges.
- Explore security practices, like sanitizing inputs for tools like the calculator or file reader.

By experimenting with these ideas, students can transition from building simple agents to creating sophisticated, practical AI systems tailored to real-world needs.